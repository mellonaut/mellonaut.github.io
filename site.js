const posts = [
  {
    id: 1,
    title: "Straylight Blog: An Anthology of Failures",
    date: "2023",
    description: "<p><h1>Dev. Sec. Oops.</h1><p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/lich3.jpg' alt='Description of the image'><p></p>A development blog, personal and technical, with a focus on Microsoft security and the Azure cloud. Purple Team Stories, demos, bad memes, and code review. This will will help track my progress, let me do in depth write-ups on some of the tools I've made over the last couple of years to help myself and share cheatsheets, code and techniques that have worked for me lately. So much of learning security is reading old blogs, and new blogs based on the old blogs. Maybe someone finds something in this useful. <p></p><h3>Github</h3><p><a href='https://github.com/mellosec'>Mellosec - Coding Projects</a></p><h3>Certifications:</h3><p><a href='https://training.zeropointsecurity.co.uk/courses/red-team-ops'>(In progress) CRTO - Certified Red Team Operator</a></p><p><a href='https://learn.microsoft.com/en-us/certifications/exams/sc-200/'>MS SC-200 - Microsoft Security Operations Analyst</a></p><p><a href='https://elearnsecurity.com/product/ejpt-certification/'>eJPT - eLearnSecurity Junior Penetration Tester</a></p><p><a href='https://learn.microsoft.com/en-us/certifications/exams/az-104/'>AZ-104 - Azure Administrator Associate</a></p><p>Email: <a href='mailto:mellonaut@straylightsecurity.com'>mellonaut@straylightsecurity.com</a></p><\/p>",
    image: "https://dev.straylightsecurity.com/assets/straylight.jpg",
    clip_path: "polygon(50% 0%, 100% 50%, 50% 100%, 0% 50%)"
  },
  {
    id: 20,
    title: "Graboid and Pipelines: Iterations on a Stealer",
    date: "September 28 2023",
    description: "<><h1>Thievery Corp</h1><p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/graboid/Sorrowset-V3.png' alt='Description of the image'><p></p><p>Stealer malware has seen a huge surge in the last year, as modern security solutions begin to close the gaps around initial access with EDR/XDR and the signaturing of new C2 frameworks as they are released, even custom code, if it's delivered via O365 will get caught between Defender for Office, Defender for Endpoint, Defender for Cloud/Apps, etc, depending on what it tries to do and how it does that. I got really stuck on wanting to write a payload that flew a little but under the radar. I spend a lot of time hacking myself and writing detections, I wanted some tools of my own, and to learn how to integrate them. I ended up with a modular design for an assembly loader with stagers and Azure Function redirectors. It would pull it's componenets through the redirector and load them in memory to keep them off of disk. It was a long road, completely re-written three times over months to get to get to something decent. This was my first introduction to unit/integration tests and maintaining a decent sized application correctly in a DevOps pipeline. I had to get a flask backend and reverse proxy working with serverless redirectors and C# implant, that became slimmer and slimmer as I offloaded more processing to the backend. Eventually the stager opens the decoy PDF, checks in and loads whatever is waiting in the main method of the library, and does little else itself, relying on modules for all of its functionality. I can change what stages I want to execute, if any, in what order by pushing code to the repo. Devops platform picks up the changes, obfuscates, builds, tests, does further processisng to steal signatures of winword.exe, encrypt and encode, etc. If tests pass, it will deploy live where the stager or sleeper can check in to run a new routine. The automation has saved me so much time and frustration, unit testing and integration tests feel like this new gift from god now that I understand my own code a little bit better. Writing unit tests was a bit weird, so I wanted to cover the devops side of this as much the malware, maybe more. Let's dig in and check it out.</p><p></p><h2>The Problem</h2><p></p><p> This thing originally started dead simple: Run, POST to a webhhook. I was so frustrated with C2 implants and loaders and out-dated evasion techniques and all the pentester tears that come with god damn EDR. I just wanted something to run to prove that the download was followed through from click to execution. It didn't need to even open a shell. Please, just, a piece of something...</p><p>A C# binary that POSTs to a url is...well, it's C# so it still takes up a whole page, but as simple as you can get for a client. The server was something new for me, and since I'd had some luck with Flask over the last few projects, I decided to pull from that and create a service I can run in a TMUX session that just waits for connections, looks for my special headers, ignores everything else, and logs the activity. Flask is really straight-forward and if you need to get some mini-api deployed that does one or two things, I can't recommend it enough. It's been easy to pick up and trouble-shoot, way easier than dotnet. Pretty quickly we got some code together to enumerate a couple of things, I wanted to see about POSTing system information as a parameter. It went smoothly, cookies did not, but I was able to get them working using the old, janky .Net Serializer:</p> <p></p><img class='post-article__image' src='assets/graboid/graboid1.png' alt='Graboid'><p></p><p>   One of the reasons we're stuck with the serializer rather than NewtonSoftJSON (it's way better) is to keep everything as close to what's already there in Windows. Every Windows device will have .NET 4.8~ at least, so we try to target the widest possible release, on the most systems, so as to avoid re-factoring multiple times. It's ugly, and there is a point where it got problematic, as my JSON strings weren't good enough for my server to parse. Some fiddlywork later we got back on track. Here's server code at the time, this was version 3.</p><p></p><img class='post-article__image' src='assets/graboid/graboid2.png' alt='Graboid'><p></p><p>If you followed my silver-linings CORS and Capture series, you'll recognize parts of this. I lifted and modified a lot of that code to get this.  Funny enough, a few weeks ago I watched a Black Hills talk that led me to believe that  I was wrong, what I was trying to do there still works, I just couldn't figure out the last piece. I still can't. But I know what to try, I think.. I have to stay on track to fiinish this, but man, I'm going back to that next. If I could get that working I'd have my ideal setup. Anyway, this is going behind the reverse-proxy caddy, which will handle the routes and access control, passing the traffic to the Flask app on the backend. Same way we did it for the CORS server, Updog, token captures. It's beyond the scope of this post but I drone on and on about it in that 3 part CORS series if you're interested.</p><p></p><h2>The Progression</h2><p></p><p>This is the first design of three, and three has been completely re-written once and re-factored since.</p><p></p><img class='post-article__image' src='assets/graboid/graboid3.png' alt='Graboid'><p></p><> I've been on this for months, working on different ways, running into different problems. I still have a ton to learn. This period has been a real meditation on initial access. I realized I learn most things with a coding/scripting project now, it slows my whirlybrain down enough to absorb the details I sometimes miss otherwise. If you mess up, it won't compile, or it will, and embarass you, so I've gotten to know a general rule for me: it's the third one. You do it once, you have no idea exactly what the problem is, and how to solve it, but you know enough to keep trying. You end up with this thing that looks like my old tent when I'd go camping, it just kinda sprawls out to the side and the second you start moving stuff around it'll collapse on you. Version 2, you go apeshit on stakes, because you know how they work now, so watch out. You over-engineer (nest shit), use twice the variables you really need to, and somewhere around the 30th unique, nitpicky class, inheritance and interfaces start to just click in your head, if you're me, at least. After a year of OOP with C#/PoSh and a little python, concepts started to really click on this project. It's hard to explain but you start having this mental representation of waht the language does and doesn't do, and as you get better and learn more, you see new parts, but you also view old parts in new light, and get a more comprehensive picture of what's possible and why you should do it. It's called Dependency Injection and I was too lazay to re-work what had become a substantial amount of code. I didn't think I had time to re-factor, but if I had, I probably wouldn't have broken my project so bad, and avoided the lil baby tantrum that followed in its wake.. Let's see if we can find that point in the commit history or in some code, show you guys what not to do with classes in dotnet. And what not to do with commit comments. You should be mindful to never blast a group project with your f-bombs, meltdowns and hilarious lamentations in the commit history, but if you do, do it in 'Main'. </p><\/p>",
    image: "https://dev.straylightsecurity.com/assets/graboid/Sorrowset-V3.png",
    clip_path: "polygon(50% 0%, 100% 50%, 50% 100%, 0% 50%)"
  },
  {
    id: 21,
    title: "Sleeping Giants II: Failing Forward",
    date: "July 18 2023",
    description: "<p><h1>Learning the Hard Way</h1><img class='post-article__image' src='assets/sleeping2/sleeping1.png' alt='Phlegm's Art Rules'><p>It's been some months, a bunch of failure, a bit of success, a lot of learning and a few new tools. I wanted to write about some of the problems I've run into since then and recreate them in the lab so we can work through solutions. We learned (and re-learned) how to pick a good domain. We covered reputation, then we learned the hard way about categorization. We grabbed a new domain with good reputation on expireddomains.net, after using <a href='https://www.cyren.com/security-center/url-category-check-gate'> Cyren Category Check Gate</a> to check what it was already categorized. We got our mail records set up correctly, verified with mail-tester.com. Once our score was up, we tried hosting some dynamic device code phishing pages and spent a while learning azure app service. We learned a bunch of css and javascript, weirdly enough. Worked out our next pretext and supporting assets. TrustedSec has a blog that a good friend who's farther along this path shared with me <a href='https://www.trustedsec.com/blog/upgrade-your-workflow-part-2-building-phishing-checklists'>Phishing Checklist</a> and it has a reputation checker with email as well.</p><p><img class='post-article__image' src='https://www.trustedsec.com/wp-content/uploads/2020/03/HansB3.png' alt='TrustedSec'></p><p>He told me he had recently had to get one of his domains categorized and shared this article with the advice that it was old and some of the information is outdated, but go for Financial or Health Care. We need to get those domains that were good for pretexts categorized to bypass webfiltering. I figure it would be a good idea to document the process to help out others. Maybe it takes you a little less time to get up and running.</p><p><h2> Re-Categorization </h2></p><p>We need to get a maintenance page up saying our company is in the financial sector. It doesn't need to be much, but it should be hosted with a verified SSL cert and look the part. Azure Static Web App is an easy way to accomplish this and one I've taken to using a lot.</p><p>I went to google and looked for some 'under construction' graphics, borrowed them and created a page with 'Alluring Company - A Leading Name in Financial services to the X industry' where X is whatever you're pretext involves. You can use this, just…please edit it and don't forget the 'title' tag. It's on this site under 'assets/construction.html'</p><p><img class='post-article__image' src='assets/sleeping2/html.png' alt='Sleeping Giants 2'></p>Which renders into this site.<p></p><img class='post-article__image' src='assets/sleeping2/sleeping2.png' alt='Sleeping Giants 2'><p></p><p>The Finance and Health categories are least likely to be blocked as many places have laws or regulations against preventing employees from accessing their bank or medical records. We want it to seem good enough that it passes review when we ask to get recategorized. We want a good domain, a legit under maintenance page. You'll need an email as the point of contact. When you have some HTML together, upload it to a github repository. Azure Web Apps can deploy directly from the repo to a site with a custom domain and SSL binding, we'll use this to host the maintenance page for re-categorization as well as HTML smuggled payloads later.</p><p></p><img class='post-article__image' src='assets/sleeping2/sleeping3.png' alt='Sleeping Giants 2'><p></p><p>Fill out and add your github repo under Deployment Details.</p><p></p><img class='post-article__image' src='assets/sleeping2/sleeping4.png' alt='Sleeping Giants 2'><p></p>It will give you a CNAME record for your DNS provider.</p><p></p><img class='post-article__image' src='assets/sleeping2/sleeping5.png' alt='Sleeping Giants 2'><p></p><p>Type out a subdomain for your onboarded custom domain. If you already added 'yourdomain.com' to the tenant, you would go for something like this.</p><p></p><img class='post-article__image' src='assets/sleeping2/sleeping6.png' alt='Sleeping Giants 2'><p></p><p>It will give you some information to post at your DNS provider to link the static app with your domain.</p><p></p><img class='post-article__image' src='assets/sleeping2/sleeping7.png' alt='Sleeping Giants 2'><p></p><p>Create your records, verify, then we can start submitting it. We go to each vendors site and submit our domain to be look at again. Use the company email we set up earlier for the point of contact so you can reply if someone has any questions.</p><p>Let's do Fortinet, the link to what I used is Web Filter Lookup | FortiGuard</p><p></p><img class='post-article__image' src='assets/sleeping2/sleeping8.png' alt='Sleeping Giants 2'><p></p><p></p><img class='post-article__image' src='assets/sleeping2/sleeping9.png' alt='Sleeping Giants 2'><p></p><p>It took a couple of days once I got my site up and reached out to the different vendors. They checked the site, sent me an email and that was basically it. When Fortinet emailed me, I tested it from behind the fortigate I have in my lab. One layer down, on to the next. </p><h2> Stealer and Webhook</h2><p>I was having a hard time getting payloads by EDR. I was using API calls that were targeting NTDLL and calling Nt functions for allocating memory and execution. This worked well against regular AV but Defender for Endpoint flagged it and caught the amsi/etw tampering. EDR is forcing people to target deeper components like the NTAPI or even now the EFIAPI  with toolkits like Black Lotus targeting firmware. By using kernel mode drivers, attackers gain access to lower and lower systems and can perform exploitation and persistence before kernel protections, bitlocker and secureboot.</p><p>We're going to try having a relatively harmless payload, signing it with a microsoft signature and tampering with the size. I used a tool by mgeeky called 'Bloated-Exe-in-LNK' to get our  'stealer' malware packed inside an LNK that will drop a zip file to TEMP and execute the exe. I used .Net Reactor to obfusacate and protect the binary, it's very similar to ConfuserEx and will obfuscate biinary against analysis. The trial version only allows 14 days until you have to recompile the payload.</p><p>It's not stealing much of anything to start, just doing host recon and getting the public IP address of the user and sending that off to a webhook. The webhook is a small flask app behind a reverse proxy waiting for POST requests, a sysinfo parameter and a secret header. Sysinfo is the collection of system information the stealer gathers, serialized into a json object. I think our next iterations will be to base64 encode before sending and decode on the flask server.. Let's look at our bare bones version of the server.</p><p></p><img class='post-article__image' src='assets/sleeping2/sleeping10.png' alt='Sleeping Giants 2'><p></p><p>We run it on port 3000 and use the same SSL certificates we use for the reverse proxy (Caddy, check out 'CORS and Capture' series for all that). We updated our Caddy config to proxy requests  . This is a simple version if you want to do the same, that way you can host multiple services behind the proxy instead of this being entirely a webhook. Run 'python3 app.py' from a tmux session and use this for your Caddyfile:</p><p></p><img class='post-article__image' src='assets/sleeping2/sleeping11.png' alt='Sleeping Giants 2'><p></p> <p>That handles requests to the path '/hook' and serves them to port 3000 where our app is waiting for the POST. It preserves the X-HOOK-TOKEN header values and skips TLS verification check to post the object. May not be needed with our current configuration but I leave it unless it breaks something, like everyone in IT.</p><p>The C# code is barebones, too. I don't want it to anything even remotely suspicious. That POST request could be a GET instead, and we could use deeper API calls here. I want to start simple, basic, and see where EDR starts hating us. Let's check out the sysinfo object:</p><p></p><img class='post-article__image' src='assets/sleeping2/sleeping11a.png' alt='Sleeping Giants 2'><p></p><p></p><img class='post-article__image' src='assets/sleeping2/sleeping12.png' alt='Sleeping Giants 2'><p></p><p>Now that we have our plumbing, we can string it all together in the Main method.</p><p></p><img class='post-article__image' src='assets/sleeping2/sleeping13.png' alt='Sleeping Giants 2'><p></p><p>I already see ways we can make it better. There's some jankery in gathering and returning the identity in the WhoAmi method, and this is not proxy aware, whichwe'll need eventually. For what we need and when we need to start it, it's fine. </p><p>I'm going to inflate the binaries size to over 100 MB. I read that EDR has trouble with these bloated binaries and will ignore them, but I'm not sure the size. I'll try adding 125 megs and try it again at 200 if it doesn't work. We're going to steal a signature from a signed MS binary and apply it to our payload. We'll use .Net Reactor to protect, encrypt and obfuscate the binary, then  compress the bloated binary down into a small zip file and  use a tool to pack that into an LNK file that will unpack the zipped binary to TEMP directory and execute the contents in memory.</p><p><pre class='code-snippet'><p># Inflate.py - Enter an input file and an inflation size in MB.</p><p>python3 .\\inflate.py -f .\\grab01d.exe -s 120</p><p></p><p># SigThief</p><p>$exe = '.\\OneDriveSetup.exe'</p><p>python3 .\\sigthief.py -i $exe -t Grab01d.exe -o grab01d_sig.exe</p><p># Protector</p><p>start-process C:\\'Program Files (x86)'\\Eziriz\\.NET Reactor\\dotNET_Reactor.Console.exe</p></pre></p><p>Reactor will start and if you've used ConfuserEx you'll know what to do.</p><p></p><img class='post-article__image' src='assets/sleeping2/sleeping14.png' alt='Sleeping Giants 2'><p></p><p>Similar things you can do as ConfuserEx. Just load your binary, choose whichever quick settings you want or use the in depth changes. It has decent documentation, way better than Confuser, you and me both could learn some things. Don't use these settings, they got me flagged. One at a time, until we understand, tedious as it is. That's what you get for reading too fast.</p><p></p><img class='post-article__image' src='assets/sleeping2/sleeping15.png' alt='Sleeping Giants 2'><p></p><p>It outputs to 'secured' folder in the assemblies folder, I renamed the file grab01d_sig_protected.exe</p><p>Now we compress and generate the bloated LNK</p><p><pre class='code-snippet'><p># compress</p><p>Compress-Archive -Path .\\grab01d_sig_protected.exe  .\\grab01d.zip -EA SilentlyContinue | Out-Null</p><p></p><p># Create bloaked Lnk to drop andls execute exe</p><p> & .\\gen-embed-zip-lnk\\gen-embed-zip.exe  .\\grab01d.zip  unsuspecting.lnk grab01d-bloated.exe</p></pre></p><p>It will output two files 'unsuspecting.lnk' which will extract 'grab01d-bloated.exe' into Temp. I added '-bloated' to the binary name to distinguish it as the output file but doesn't matter, LNK is standalone. Take the lnk and deliver, when the user runs it will extract the payload from itself.</p><h2> Selling It </h2><p> I used the adobe reader path and replaced the lnks icon with a PDF decoy, but this requires the user to have the same file on their system at that default Acrobat path. Just an FYI should you choose to use it. I'll show you another way later.</p><p></p><img class='post-article__image' src='assets/sleeping2/sleeping16.png' alt='Sleeping Giants 2'><p></p><p>I used ImgBurn to create an ISO file that contains that LNK file looking as a PDF and favor HTML smuggling, so we need to convert the ISO into base64.</p><p><pre class='code-snippet'><p># Define the file path</p><p>$filePath = '.\\calendarpreview.pdf.iso'</p><p># Read the file as bytes</p><p>$bytes = Get-Content -Path $filePath -Encoding Byte</p><p># Convert the bytes to a Base64 string</p><p>$base64 = [System.Convert]::ToBase64String($bytes)</p><p># Output the Base64 string to b64.txt</p><p>$base64 | Set-Content -Path 'calendarb64.txt'</p></pre></p><p></p><img class='post-article__image' src='assets/sleeping2/sleeping17.png' alt='Sleeping Giants 2'><p></p><p>And place the data into the script so our javascript can decode and deliver.</p><p></p><img class='post-article__image' src='assets/sleeping2/sleeping18.png' alt='Sleeping Giants 2'><p></p><p>When the user visits this page, the base64 is converted and dropped to disk without asking, the user then only has to open the file to mount the iso. Once mounted, the lure is a pdf in a folder, nothing crazy. Double-clicking the lnk will unpack the payload, run it and we'll get our sysinfo object posted to our webhook.</p><p>Defender caught the protected binary. I went back and tested with different versions, it's something we did with .Net reactor. I'll try going one by one for another post but for now we can do without. The bloated lnk itself worked and got by defender, executing our stealer. The problem is getting the lnk to the user. Mounting the iso from my EDR test machine gave an error that I didn't have the privileges to mount. </p><p></p><img class='post-article__image' src='assets/sleeping2/sleeping19.png' alt='Sleeping Giants 2'><p></p><p>It let me after another try, but it's not ideal. It's an option, I remember users who would definitely keep trying. Then I tried putting it inside a zip file, but Defender triggered on the lnk execution inside of the zip.</p><p></p><img class='post-article__image' src='assets/sleeping2/sleeping20.png' alt='Sleeping Giants 2'><p></p><p>I ended up placing the exe inside of an zip file and base64 encoding it. Test cases got by Defender so I wanted to try it. It looked sketchy to me, but who knows.</p><p>Checking the webhook..</p><p></p><img class='post-article__image' src='assets/sleeping2/sleeping21.png' alt='Sleeping Giants 2'><p></p><p>Our simulation stealer checked in okay. When we deploy the next version of the stealer in a week or two we can work on a better package. Let's check this against the EDR and see if it runs, then see what we see on the devices timeline.</p><p>We had no trouble running it as a user, stealer checked in and rained cookies down upon us.</p><p>No alert, but there are ways we can improve this payload either way. I want to know what every step looks like in EDR, so using our Defender for Endpoint trial we can check the devices timeline. We need to fix the name and recompile it to make the names match, for one.</p><p></p><img class='post-article__image' src='assets/sleeping2/sleeping22.png' alt='Sleeping Giants 2'><p></p><p></p><img class='post-article__image' src='assets/sleeping2/sleeping23.png' alt='Sleeping Giants 2'><p></p><p></p><img class='post-article__image' src='assets/sleeping2/sleeping24.png' alt='Sleeping Giants 2'><p></p><p>Here's the behavior on the timeline.</p><p></p><img class='post-article__image' src='assets/sleeping2/sleeping25.png' alt='Sleeping Giants 2'><p></p><p>Starting from the bottom we can observe explorer.exe creating the process for the exe. It creates a new console (conhost) loads a bunch of system dlls and checks in with dyndns to obtain the public IP for the host. It failed a couple of times, then made it, loads some more DLLs we need as it grabs additional host information, then we see a flag here for the decryption of the sqliteDB holding the edge cookies.</p><p></p><img class='post-article__image' src='assets/sleeping2/sleeping26.png' alt='Sleeping Giants 2'><p></p><p>You'd think that's a red  flag or something, but I see them all the time in benign context. A lot of microsoft products look very sketchy. Even before all the recent sideloading, Teams activity made me nervous. If there was no alert attached to that behavior I would have to be actively threat hunting to catch this, and that would require a lot of time (and skill) I don't really have. We have something to look at, though, we can use it to both improve our payload and write a detection that might catch it. Eventually we'll rewrite this in syscalls and see how that looks, too. Next is the actual stealer POSTing to the webhook.</p><p></p><img class='post-article__image' src='assets/sleeping2/sleeping27.png' alt='Sleeping Giants 2'><p></p><p>Pretty good start. The only problem I found was the zip file. It doesn't do us much good anymore, mark-of-the-web is propagating to what's inside but the zip won't auto execute it's contents. The user has to extract the file. We need to re-encode and smuggle the EXE directly from the Azure web app like we are. Before we re-compile and de-deploy, let's upgrade the payload and server, then get an icon of a PDF and see if we can make the exe look more runnable. </p><h2>Version 4 / Server 4</h2><p>We added a mutex to make sure there's only one instance of graboid running at a time and implemented stealing cookies from Edge, and Chrome if installed. We modified the server to accept another parameter. The stealer code is too much for this article but look at Umbral builder/payload and you'll get an idea. The Browsers classes in that project made this pretty straight forward, the bitch was in dealing with JSON while only using what's included in .Net Framework 4.5.3..I went through hell trying to get it POST a valid JSOn object that my server could parse. Eventually I retargeted the project to .Net 4.8 which has the using System.Web.Script.Serialization class which was a lot better to work with. It took about 10 minutes once I switched. </p><p></p><img class='post-article__image' src='assets/sleeping2/sleeping28.png' alt='Sleeping Giants 2'><p></p><p></p><img class='post-article__image' src='assets/sleeping2/sleeping29.png' alt='Sleeping Giants 2'><p></p><p>Get the Edge cookies, try for Chrome, serialize the results and initialize the first web client for the sysinfo, clear the headers and POST the cookies. HTTP is stateless, we can't (and shouldn't) try to re-use the webclient / headers. Any object we create that we want transferred to our server is going to need one.  'cookiesPayload' and 'cookiesPayload2' are Edge and Chrome. Eventually we'll have 'edgeCookies' 'chromeCookies' with matching parameters in flask so that we can have them organized.</p><p></p><img class='post-article__image' src='assets/sleeping2/sleeping30.png' alt='Sleeping Giants 2'><p></p><p>Minor changes to the server code:</p><p></p><img class='post-article__image' src='assets/sleeping2/sleeping31.png' alt='Sleeping Giants 2'><p></p><p>And the result.</p><p></p><img class='post-article__image' src='assets/sleeping2/sleeping32.png' alt='Sleeping Giants 2'><p></p><p>And some powershell to parse for the established Auth/Persistent Auth tokens, the ones that will allow us to log in as users.</p><p><pre class='code-snippet'><p>$logFilePath = 'log.txt'</p><p># Read the log file</p><p>$logContent = Get-Content $logFilePath</p><p># Filter for lines containing the desired names</p><p>$filteredLines = $logContent | Where-Object { $_ -match 'Name: </p>(ESTSAUTH|ESTSAUTHPERSISTENT)' }</p><p># Format the filtered lines as a table</p><p>$table = $filteredLines | ConvertFrom-String | Format-Table -AutoSize</p><p># Convert the table to a string</p><p>$tableString = $table | Out-String</p><p># Save the formatted output to the output file</p><p>$tableString | Out-File -FilePath $outputFilePath</p></pre></p><p>This will extract the two cookies we really want, the login cookies for the user. The PERSISTENT variant is the one you get when you check 'Keep me signed in'.</p><p></p><img class='post-article__image' src='assets/sleeping2/sleeping33.png' alt='Sleeping Giants 2'><p></p><p>Version 5 of the stealer will aim to be stealthier and Version 5 of the server more efficient at serving us tokens. Self-Hide, self-delete. We can either have flask kick off that powershell script or parse the JSON by itself. Cookies come in, the good ones go out, cat the log, profit. It would be nice to embed the decoy pdf file for the calendar and have it decode, drop to disk, open for the user and then delete itself, leaving a PDF in it's place essentially.</p><p>For now, let's get an icon set up, change the assembly name and re-package.</p><p></p><img class='post-article__image' src='assets/sleeping2/sleeping34.png' alt='Sleeping Giants 2'><p></p><p>Now go to 'Project>Properties' and select your converted icon file.</p><p></p><img class='post-article__image' src='assets/sleeping2/sleeping35.png' alt='Sleeping Giants 2'><p></p><p></p><img class='post-article__image' src='assets/sleeping2/Sleeping36.png' alt='Sleeping Giants 2'><p></p><p>Skip the zip this time, run sigthief.py and inflate.py to get the binary size up, then base64 encode it into a file.</p><p>Powershell struggled with the large binary size converting to bytes, if you run into the same problem use wsl/linux and 'base64 -w 0 calendarpreview.exe > calendarb64.txt'. Once we have our b64 blob, replace it in the html file and change the MIME type from compressed to octet-0stream. This ensures the exe will be downloaded as an exe for execution. Make sure the extension matches on the line below.</p><p></p><img class='post-article__image' src='assets/sleeping2/Sleeping37.png' alt='Sleeping Giants 2'><p></p><p>Just to save us time later, I made some variations, small, big, zip, .one note file, etc, and embedded them in their own pages. Options within options. Now that device codes and a payload are figured out, we can revisit Evilginx.</p><p><h3>To be continued, here or elsewhere.</h3><p></p><img class='post-article__image' src='assets/lich3.jpg' alt='Sleeping Giants 2'><p></p><!--Last paragraph break--></p>",
    image: "assets/sleeping2/sleeping1.png",
    clip_path: "polygon(75% 0%, 100% 50%, 50% 100%, 0% 50%)"
    },
  {
    id: 22,
    title: "CORS and Capture 3: Another Brick in the Wall",
    date: "June 30 2023",
    description: "<p><h1>Another Brick in the Wall</h1><p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/automateautomate.png' alt='Description of the image'></p><p></p>Welcome back to part 3 of this series where we're developing a solution for serving a dynamic device code page and retrieving the token from the endpoint.This let's us get arounds the 15 minute time-to-live that was bothering me so much. The first two arts saw us develop our proof-of-concept and get through the hurdles to having it run.We touched briefly on the deployment of these servers and the scripts and I apologize for that, it's hard to decide when to go into what as we covered a bunch of topics on this project. This article will go itno more detail on that and demonstrate deployment through the full attack chain for this setup, how to use it, etc.<p></p>Infrastructure-as-Code<p></p>Infrastrucutre-as-Code, or IaC, is writing repeatable deployable infrastructure as sets of scripts or configuration files. The cloud age has ushered in a sea of powerful APIs into every providers heart and it's allowed engineers and admins to approach infrastructure in a different way. There are many ways to do it but my preferred ways are a combination of powershell, terraform, ansible and various providers individual CLIs. Azure is a good example, I'll use small powershell wrappers to automate terraform tasks and use ansible to do post-configuration. It was my introduction to coding and has saved me a HUGE amount of spend on cloud resources. Having terraform/ansible combo configurations for most of my needs has been great. I can store the data in the cloud and spin up whatever I need and attach. If I'm going to spend more than an hour troubleshooting something I'll often detach the public IP and volume, blow it away and attach them to the new one. You keep your code in github and have version control, as well as a means to continuously deploy  through Actions or Azure Devops (I'll show you it's awesome). This project contains examples in the forms of powershell scripts for azure and aws that are easy for you to modify and make your own plus an eample of a terraform+ansible project you can use as well.<p></p><h2>Deployment</h2><p></p>Let's diagram and deploy our capture server, then our lure server, then we'll demonstrate. This won't be an in depth powershell tutorial, I'm going to show you where you can make some edits and some gotchas that may pop up.<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/solutiondiagram1.png' alt='Diagram'><p></p>Here's where we ended up.<p></p> We started with CORS on both servers as we developed the concept, but reducing that to just the lure server behind a reverse-proxy was the best solution. We reduced the size of the capture server to save costs and have the lure-server providing extra utility as an Open-Redirect for disguising urls. If you're wondering why we don't capture the tokens behind Caddy: I don't want a single point of failure and decoupling phishing from capturing is worth it. The capture server uses Azure's IP reputation and backs the LetsEncrypt cert to retrieve our tokens and our good categorized domain goes on AWS to host the lure. Let's try the capture server first, since that's working already. We just need to make some edits for our custom stuff.<p></p><h2>Capture Server</h2><p></p>We touched on this briefly in the first couple of articles, it's an Azure VM that captures the tokens, deployed using powershell and Az Run-Command to configure it.<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/capture1.png' alt=';Cors and Capture 3'><p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/capture2.png' alt=';Cors and Capture 3'><p></p>We still clone TokenTactics and TokenTacticsV2 like we did but we've added our cors repo and pointed the sections about the capture server to our version located in 'yourcorsanywhere/capture-server/capturetoken.py'. It will create it's own LetsEncrypt certificate and we copy that now to our repo since we're serving with those certificates. I included '.pem' in the .gitignore to be safe, but don't make any commits from this server. Consider it a one way repo, clone it, make your changes for the operation and use it temporarily. Don't push secrets, you get really big  bills and none of the mined crypto. Trust me..<p></p> We then use tmux to create the session for the capture server. My friend showing me Tmux was a true gift, it's made my life so much easier. You can log into your server and create a persistent session for each thing you want to run. If your shell dies, it will still run until shutdown or closed, but it's not as bulky as running it as a true service. For what we do it's perfect and the fact that it's scriptable is really cool. I've never tried it in an azure deployment so let's we what we get.<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/capture3.png' alt='Cors and Capture 3'><p></p>Deployed, but without tmux. Let's delete the entire resource group to clear out the resources, look for typos and re-deploy.<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/capture4.png' alt='Cors and Capture 3'> <p></p>And Redeploy:<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/capture5.png' alt='Cors and Capture 3'> <p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/capture6.png' alt='Cors and Capture 3'> <p></p>I love Az Run-Command, I wish AWS had an equivalent. If you can shell script or know powershell it makes deploying VMs and post-config a breeze.<p></p>AADInternals wouldn't import<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/capture7.png' alt='Cors and Capture 3'><p></p>It says succeeded, because it ran the command, not because the command itself was successful. You have to look through them a bit to find things. Comment out that section for now, we'll run those manually on the host after it deploys and fix them back here<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/capture8.png' alt='Cors and Capture 3'><p></p>There were some quotes, typos and variable issues I fixed, I just wanted to show you the basics of troubleshooting so you can modify and use this.<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/capture9.png' alt='Cors and Capture 3'><p></p>This one drove me a little crazy. You have to start powershell and install in the same command so it's in the same powershell session, if you try 'pwsh' as one command and the 'Install-Module' as two commands, i.e. like I tried 'pwsh; Install-Module'. It wants the commands one by one. Trying 'pwsh && Install-Module' didnt work either. You need to pass the '-c' argument to tell it we want to start powershell and specify a command for powershell to run.<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/capture10.png' alt='Cors and Capture 3'><p></p>We got it working, we logged into the server and verify tmux session is active, but not serving flask.<p></p>To troubleshoot, let's try and run the command.<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/capture11.png' alt='Cors and Capture 3'><p></p>We had python instead of Python3. Gets me all the time. Helps to be specific. We still ended up having trouble with sending the tmux command through run command. I'm okay with needing to start the capture session manually, I'll auto-shutdown/redeploy everyday anyway, but I'll put some time in trying to figure this out later on.<p></p><h2>Lure Server</h2><p></p>This was pretty straight forward, AWS makes it easy to deploy, as well, though, you can't just run commands on a VM. You have to supply a shell script in the form of user data:<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/lure1.png' alt='Cors and Capture 3'><p></p>Pass your access keys on the command line, it's very not secure, buyt secrets management is up to you, that's beyond the scope of these articles. That will be a future article, though. We create a new SSH Keypair for this and write it to our SSH folder.<p></p>ProfileName and, Tags, UserDataScript are all yours to change. That AMI is the Id used by AWS for the ubuntu image in us-east-1. Parameters passed to the aws cli as a hash table. Change 't2.nano' to 't2.micro' if you find this machine needs more juice. I'm trying to save as much money as we can, but I noticed when we had everything running during development the lure-server was starting tp feel it. That's the beauty of I-a-C, though, just blow it up and re-deploy.<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/lure2.png' alt='Cors and Capture 3'><p></p>Security Group Rules<p></p>We get the instance by using our Tags, the Name LuridArray, and retrieve it's security group. We then open our we bports to the world, then get our public IP and store it in a varialbe to create the SSH rule for your current IP. This way your SSH isnt exposed to the world. We'll add this to the Azure VM deploy, too. <p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/lure3.png' alt='Cors and Capture 3'><p></p>Worked like a charm. The deploy script is the next step, make sure it's doing what it should. We're going off the default AWS username here and you have to set your domain for the certbot portion to get your SSL cert. Caddy has automatic letsencrypt enrollment, I think that may be a good thing to try. We know certbot works but with some manual intervention on our part. I wonder how caddy does it's thing.<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/lure4.png' alt='Cors and Capture 3'><p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/lure5.png' alt='Cors and Capture 3'><p></p>Very cool. Right now, we're providing the domain but overriding this activation feature using our own certificates, which we specified in the Caddyfile:<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/lure6.png' alt='Cors and Capture 3'><p></p>We also developed this on a blowaway machine I manage with ansible, so our username is going to need to change. We could standardize the username between both projects or do like 'capture' and 'lure' instead of platform specific. <p></p>It's a little much for this article, but the way I see doing CORS and Capture in the future is a single Terraform configuration file with both servers and respective DNS providers. We would add the DNS record at the VMs creation. This would work like the azure capture server, we could use caddy to enroll based on the AWS DNS information. I want to use our custom domain certificate, though. We still end up in a situation where we need the IP address to make the record before we can continue with the script. It's not a big deal, it can he handled similar to this:<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/lure7.png' alt='Cors and Capture 3'><p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/lure8.png' alt='Cors and Capture 3'><p></p><h2>Live Test 3</h2><p></p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/lure10.png' alt='Cors and Capture 3'><p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/lure11.png' alt='Cors and Capture 3'><p></p>Access to XMLHttpRequest at 'https://login.microsoftonline.com/common/oauth2/deviceauth?code=FNFXM529T' from origin 'https://test.straylightsecurity.com' has been blocked by CORS policy: Response to preflight request doesn't pass access control check: No 'Access-Control-Allow-Origin' header is present on the requested resource.<p></p>I thought we had that set on the server. Let's take a look, maybe we have stripped them out and didn't notice.<p></p>Everything looks fine, though...<p></p>Let's test it against the control.html, which is the original snippet, and validated-test.html the one that was working and gave us the token in Part 1.<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/lure12.png' alt='Cors and Capture 3'><p></p>That is the same damn error, and on both. I really, truly, hope Microsoft didn't patch this between part 1 and part 3. Some troubleshooting on both sides has me concerned that may be the case.<p></p>We could try to deploy standard cors-anywhere again and remove the Caddy, see if we can make this work. Thoughts are we could maybe have Caddy add the header but I'm really not sure. This just sort of sucks.<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/lure13.png' alt='Cors and Capture 3'><p></p><p></p>CORS is working here, that's a response using our cors server to request the token from the endpoint. Let's see what happens if we add the headers via the proxy.<p></p>Nope.<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/lure14.png' alt='Cors and Capture 3'><p></p>Me, google and chatGPT have reached our limit. It's a pre-flight error, I'm 99% sure it's microsoft responding to user/me saying this site can't login for you. I wonder what it was like before, I wish I had logs from last week. I kept every working version of this thing, even running the version I had that captured the tokens for the image in the first article no longer works. Microsoft may have restricted their CORS policy on that endpoint. There is another endpoint and a couple things to try but we may be right were we were last month with 15 minutes time to live for each code.<p></p>Well…we have another server on azure, we can try the setup over there. Maybe our server got blocked, or domain, or maybe Microsoft is less restrictive with requests originating from and going to it's own cloud. If that doesn't work, we're going to have to adapt, I have the new campaign together now and will have to start sending emails, waiting till we get a reply THEN sending the code while they're sitting there. I really need to understand this error before we do anything else.<p></p><p></p><h2>Into the Labyrinth</h2><p></p>Time to start looking at documentation or blog posts. I'll usually look for blog posts first, they often contain deeper break downs in the article about the topics we're looking at. I started by googling the error message. I found some blogs that deal with similar CORs issues, and provided me the deep dive I'd really been looking for. It's called stackhawk by an Application Security guy and it's really good stuff:<p></p>This excerpt from his blog got me thinking about revisitng trying to add the headers.<a href='https://www.stackhawk.com/blog/what-is-cors/';'>Stackhack: What is CORS?</a><p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/lure15.png' alt='Cors and Capture 3'><p></p>We tried doing exactly that, so maybe we should look at it again.This seems like what was working with the device code endpoint:<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/lure16.png' alt='Cors and Capture 3'><p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/lure23.png' alt='Cors and Capture 3'><p></p>I wish I was a little less of a a noob here when it comes to modern web apps. This is turning into my summer of web. We followed Stackhawk to another article referencing the exact error message we were getting.<p></p>Fixing 'No 'Access-Control-Allow-Origin' Header Present' (stackhawk.com)<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/lure17.png' alt='Cors and Capture 3'><p></p><p></p> That pre-flight request is generating the XMLHttpRequest error. The browser is not seeing a header it's expecting to see. Can we trick it? Does the value of that header really matter-matter or does it just check that something's there? They're using NGINX like we're using caddy, they're adding and handling the headers for requests and responses. We should modify their nginx config for Caddy and see what we get.<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/lure18.png' alt='Cors and Capture 3'><p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/lure19.png' alt='Cors and Capture 3'><p></p>In nginx speak, add_header is the same as Caddy's reverse_proxy directive 'header_up' and proxy_set_header is our 'header_down'. We spent some time trying different headers being passed down both sides. The header needs to be present on the login resource. It's not anymore. <p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/lure20.png' alt='Cors and Capture 3'><p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/lure21.png' alt='Cors and Capture 3'><p></p>Strict origin is enforced. We even went into our CORS server under cors-anwhere\lib\cors-anywhere.js and changed the code to match our domain here:<p></p>All day, different things, to no avail. We have to give up on this, at least for a while. Maybe we'll look around and see if anyone else has come across this or ask in the Bloodhound slack channel.<p></p>Guess that's…just kind of it. It's still useful as a high reputation redirector for links (i.e. https:/goodlink.com/https://sketchyaf.net) and used for other things, as well. Learned a ton. If we ever fix it I'll do a Part 4 for this. Microsoft may have just patched that vulnerability, though. Guess we're sending codes the old fashioned way and see about setting up one of the session stealing proxies.<p></p>Maybe we can revisit this later.<p></p><h2>Resources</h2><a href='https://www.stackhawk.com/blog/fixing-no-access-control-allow-origin-header-present/'>Stackhawk has great CORS articles</a><p></p><a href='https://learn.microsoft.com/en-us/azure/active-directory/develop/v2-oauth2-device-code'>Device Code Documentation</a><p></p><p></p><a href='https://learn.microsoft.com/en-us/javascript/api/%40azure/identity/?view=azure-node-latest'>Azure Javascript API Docs</a><p></p>",
    image: "https://dev.straylightsecurity.com/assets/cors/solutiondiagram1.png",
    clip_path: "polygon(31% 23%, 90% 30%, 50% 100%, 0% 50%)"
  },
    {
    id: 23,
    title: "CORS and Capture Part 2: Proxy Wars",
    date: "15 June 2023",
    description: "<p><h1>Proxy Wars</h2><p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/8020rule.png' alt='CORS and CApture 2'></p><p>My friend once told me that projects follow an 80/20 rule. 80% of your most important effort will go into the lat 20% of the project. That 20% of the time accounts for 80% of the value of your project. I feel like I'm butchering the hell out of that but sounds right. The first 80 percent of the project is fun and productive and morale is high.  Not that there won't be difficulties and stress or problems and redesigns, but the last 20% of a project is where it really sucks and where you learn the most. You're so over the project, you lose your shit at every git error and you're lost on troubleshooting. I think that was this past week and we're now close to the end. The last bit of suck.<p></p><h2>Where We're At</h2><p></p>This is Part 2 of a series and you might be lost if you didn't read Part 1. Last time, we started working on way to keep our device codes alive for phishing. We got a working version of the lure, but ran into the problem of sending it with the Outlook client.  We had an EC2 serving CORS solely for url redirection from a good domain. The domain had been working for email but hosting a site got blocked by web-filtering by categorization. We need to get our lure hosted on a better domain.<p></p><h2>Dog Party</h2><p></p>We ran up against a wall hosting our dynamic lure. Everything was working fine but web-filtering has the domain categorized as pornography. It was definitely not, and I requested re-categorization from that specific vendor but we need to pivot. I'm not sure what category my other domains are. Let's go take a look and see if one of the three I already bought for this will work.<p></p>Here is a site you can use to check the category of a url:<a href='https://www.cyren.com/security-center/url-category-check-gate'>Url Category Checker</a><p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/categorycheck1.png' alt='Cors and Capture 2'><p></p>All of my current ones are 'unknown' or 'parked domain'. Let's head back over to expireddomains.net. I highly suggest creating an account as you have way more options for searching. You can look for any TLD you want, .info is cheaper but .com seems more likely to be categorized. I still had to try for a bit.<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/expired1.png' alt='CORS and CApture 2'><p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/expired2.png' alt='CORS and Capture 2'><p></p><h2>Expired Domains</h2>Let's look at a good example.<p></p>Lemonwaterguide.com<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/expired4.png' alt='CORS and CApture 2'><p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/expired5.png' alt='CORS and Capture 2'><p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/categorycheck2.png' alt='CORS and CApture 2'><p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/expired7.png' alt='CORS and Capture 2'><p></p>For a breakdown of what all goes into these popularity rankings:<p></p><a href='https://labs.ripe.net/author/samaneh_tajalizadehkhoob_1/the-tale-of-website-popularity-rankings-an-extensive-analysis/'>The Tale of Website Popularity Rankings: An Extensive Analysis | RIPE Labs  </a><p></p><h2>Categories Revisited</h2><p></p>Prabably good enough for us, so let's see if it's categorized:<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/categorycheck3.png' alt='CORS and Capture 2'><p></p>It's categorized, but not into one that makes me hopeful we'll  bypass corporate filters (unless it is the c-suite).<p></p>Ultimately landed on a good reputation one categorized as 'Religious', hoping that's a category that will provide some leeway. We'll re-deploy with terraform/ansible and get a new IP and hostname then point an A Record to it for our new holy rollin' domain. Once it's all in place, we'll try from the target side again and see if they can access our page and see the lure.<p></p><h2> HTTPs and Updog </h2><p></p>Let's grab a certificate for this site, we will need it at some point, even if Updog does what we need.<p></p> I recommend certbot and LetsEncrypt, but you can do it manually, too,  if you hate yourself. Make sure you change the domain and sub to yours, run the command and make note of your cert path.<p></p><pre class='code-snippet'># Point a 'www' record to your server and run certbot with http challenge for a letsencrypt cert<p></p>domain='lemonwaterguide'<p></p>sudo certbot certonly --register-unsafely-without-email -d www.$domain.com  --standalone --preferred-challenges http --non-interactive --agree-tos<p></p></pre><p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/letsencrypt1.png' alt='CORS and Capture 2'><p></p>You'll find them in /etc/letsencrypt/live/www.$domain.com<p></p>I like to copy them to a folder in home called 'certs'<p></p><pre class='code-snippet'># Copy certs to our home folder for ease-of-use<p></p>mkdir ~/certs<p></p>sudo cp -r   /etc/letsencrypt/live/www.$domain.com/* ~/certs/<p></p>ls ~/certs</pre><p></p>Updog has it's own SSL cert it uses when you use the '--ssl' option. I'd like to use ours but it's worth trying it out. If we need to,  Nginx and another server written in Go called Gosh  let you use custom certs. It also looks like Updog is just a flask application, a framework we're fairly comfortable with.<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/updog3.jpg.png' alt='CORS and Capture 2'><p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/updog4.png' alt='CORS and Capture 2'><p></p>Note the similarities to the Capture server. Looks like we have a starting point if we feel the need to modify Updog, as well. In the morning our next objective is to test our new domain against the web-filter and the lure via Updog with SSL. If that works, we'll register a certificate for the capture server and I'll show you how to deploy it. Once we have a fully encrypted setup that works for everything, we'll do one final teardown, resize the servers for cost then deploy again and finish the automation in the process. <p></p><h2>Whiskey in the Jar</h2><p></p>Updog turned into more hassle than I had hoped for, and I recorded none of that. It occurred to me later that using CORS and Updog behind caddy as a reverse proxy would've been a better use of time. Trying that first, but I was just moving, and it may have turned into a rabbit hole we didn't need. I'm glad I did it, I learned a ton and will put some of what I made to use elsewhere. I decided to take it's source code and strip it down to do the two tasks we need: serve static content and using our own SSL certficates. We'll add strict paths to it after we prototype.<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/flask1.png' alt='CORS and Capture 2'><p></p>It's called supdog, for 'simplistic updog' but at this point it's barely an app much less a clone of updog, but I learned it from that project and I like stupid names. All you have to do is copy your 'cert.pem' and 'privkey.pem' to the supdog folder. Place static content in the same foldcer in 'static' 'content' and the filename.<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/flask2.png' alt='CORS and Capture 2'><p></p>Perfect. That's our dynamic lure serving over SSL using our LetsEncrypt certificate.<p></p><h2>Live Test 2</h2><p></p>Set an A record for our server, and went to deploy again…but I could not get the page to work, even on a local server. I ended up creating a control file in the servers static folder using the flux-hosted CORS Anywhere:<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/lureserver1.png' alt='CORS and Capture 2'><p></p>You can use this to troubleshoot with the Chrome dev tools (F12)<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/lureserver2.png' alt='CORS and Capture 2'><p></p>Let's go update our small Flask server for this file:<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/flask3.png' alt='CORS and Capture 2'><p></p>Back in our 'lure-server.js' inside '\lure-server\cors-anywhere\' we need to make some changes<p></p>Let's remove our headers, we can add them back if we need to later<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/lureserver3.png' alt='CORS and Capture 2'><p></p>Test it live against a domain we want to redirect to.<p></p>Place <a href='https://cnn.com'>CNN.com</a> at the end of your servers URL <a href='https://lure.trusteddomain.com/https://cnn.com'>https://lure.trusteddomain.com/https://cnn.com</a><p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/lureserver4.png' alt='CORS and Capture 2'><p></p>Needed to do some troubleshooting using the Console in developer tools:<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/mixed1.png' alt='CORS and Capture 2'><p></p>I think the reason it displays on the live server in VS Code but not here is that mixed content policy. I guess now we need to get SSL working. I tried before, when working out the earlier parts of this and was unsuccessful. It started turning into a time sink and I decided to pull out and work on another part of the project. Now it's unavoidable and we don't really have an excuse anyway, except the time this all has taken. <p></p><h2>Two Paths</h2><p></p>We need an SSL proxy for this Cors-Anywhere. I think we need to look at the example we first saw in the Issues of the Cors-Anywhere repo. Someone was discussing this there when I was researching how to self host this thing. It didn't work out iof the box and I didn't have what it took to troubleshoot that. If I don't have it now I'm about to get it.<p></p>The reason this was working before is because I was hosting the second cors service on Capture server.Having our resources on a separate domain prevented the mixed content error. If I was in a rush to use it, that would be my next goal, re-deploy that and edit the javascript for the hosted lure.Let's call that plan C, for cop-out, and leave it with our patient parts. Let's see if we can get this running over SSL.<p></p>We need to edit the lure-server.js first (again) to run on port 8443. We're going to run Caddy a really cool reverse-proxy that will let us proxy traffic between our cors service and the world. We won't need the custom 'straylight' headers and can run multiple services like flask and our node cors server like a backend on the same port.  <p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/lureserver5.png' alt='CORS and Capture 2'><p></p>This works. It's a basic config. It adds the required headers we need. We could easily tell it here to add our custom headers if we want to.  I'll put in the 'caddy' folder in the repo and call it 'CORS-Caddyfile'<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/caddy1.png' alt='CORS and Capture 2'><p></p>We have the proxy running on port 443 with our letsencrypt certificate and the CORS service is being proxied successfully.<p></p><h2>Updog Revisited</h2><p></p>What we're going to try today is what I should have tried earlier this week, placing updog behind the same proxy as CORS. I was having trouble with the proxy itself more than anything at that point. Looking back over everything, we had updog working, but the domain was bad. In our haste, we moved towards a seemingly 'better' solution that looked easy to implement.It looked easy, but web development is not a strong skill of mine, it's one I'm workingto improve. What this means for me is if I think the solution to my problem lies in a direction I'm 'okay' at, I should probably double the effort and triple the amount of time I think it will take to make it work. <p></p>That's definitely what happened here, I went at a new solution without knowing what complexity it was going to add, and my fundamentals were not strong enough in web to carry me through gracefully. Here I had a lot to learn, and the time it added was significant. Once again, the knowledge we gained was beyond worth it. If I had a team of operators waiting for it it would've been a nightmare, and we may have ended up with something hackier. We have the time, so we use the time. <p></p>Okay, let's move this over to the lure server and try it with updog using 'CONTENT-Caddyfile'<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/contentcaddyfile1.png' alt='CORS and Capture 2'><p></p>I took the CORS Caddyfile and made a version that should serve updog. We will have to tell it to add the ?view param later, I want to see it work in a simpler form first. Another lesson learned here is that I can't judge how much complexity a seemingly small thing can add yet.<p></p> That will come with more experience but It doesn't have to display, if everything looks right with curl we will add that later. It's easier to add another block from a stable foundation. I feel like I spend a lot of time performing surgery like a ship in a bottle trying to troubleshoot back through things I've added.<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/shipbottle1.png' alt='CORS and Capture 2'><p></p><p></p>Ensure caddy is running, start your backend cors service on 8443 in tmux session, start updog on 5000 using ssl in its own tmux session. You background a tmux session with 'Ctrl+b' then tap 'd'.  Tmux is like the vim of shells, capable of wizardy in good hands, a fumbly mess in others. It's starting to feel more natural now, for tmux at least.<p></p><pre class='code-snippet'>sudo systemctl status caddy<p></p>tmux new-session -t cors<p></p>node yourcorsanywhere/lure-server/cors-anywhere/lure-server.js<p></p># Ctrl+b +d to background tmux<p></p>tmux new-session -t updog <p></p>cd ~/yourcorsanywhere/dynamic-lures/<p></p>updog -p 5000 --ssl<p></p># Ctrl+b +d to background tmux</pre><p></p>Not a moment after shit-talking vim, I need it for something and it mangles my copy paste:<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/vim1.png' alt='CORS and Capture 2'><figcaption><i>We angered the gods. The Awk-Sed-Grep gods.</i></figcaption><p></p><h2>Development Hell</h2>Tried testing and it wouldn't work now. We had this working this morning, the same config is in place, we disabled the service, tried to load various config files manually and still got error, and rebooted because that's what you do when you're stuck. Now…<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/caddy2.png' alt='CORS and Capture 2'><p></p>We lost some time to troubleshooting this. What it was? Permission on the certificate was wrong. Caddy needed permissions. These error messages aren't very helpful. ChatGPT really helps you parse these logs and make sense of things. <p></p> <img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/chatgpt2.png' alt='CORS and Capture 2'><p></p>It can help you figure out what to google, sometimes it can answer you directly if the problem is simple or seen often enough.<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/caddy3.png' alt='CORS and Capture 2'><figcaption><i><p></p>Changed the permissions  and caddy started up, let's test the CORS proxy.</i></figcaption><p></p>sudo chown caddy:caddy /home/ansible/certs/privkey.pem<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/haackernews1.png' alt='CORS and Capture 2'><figcaption><i>We can redirect to Hacker News</i></figcaption><p></p>Let's copy the working config Caddyfile to working.Caddyfile and rename Caddyfile2 to Caddyfile. We'll put that config in the originals place and restart the service.<pre class='code-snippet'>sudo mv /etc/caddy/Caddyfile /etc/caddy/working.Caddyfile && sudo cp ~/yourcorsanywhere/caddy/Caddyfile /etc/caddy/Caddyfile<p></p>sudo systemctl restart caddy<p></p>sudo systemctl status caddy</pre><p></p><p></p>We got a 502 bad gateway error. The gateway is between Caddy and Flask. I wonder if it's with the weird updog cert.<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/502.png' alt='CORS and Capture 2'><p></p>Let's troubleshoot from the updog side first.<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/updog5.png' alt='CORS and Capture 2'><p></p>Not super proud of that folder name but I stand by it. Looks like requests are getting from Caddy to Updog. First set was with SSL and the second was attempting ssl after turned off.  An http request didn't work either. Minor change to Caddyfile to ignore SSL errors on 5000 <p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/caddy4.png' alt='CORS and Capture 2'><p></p>I moved the 'test.html' up a level so theres one in both folders and tried again...<p></p>and…<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/success.png' alt='CORS and Capture 2'><figcaption><i>Holy shit!</i></figcaption><p></p>Let's add that '?view' parameter.<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/view1.png' alt='CORS and Capture 2'><p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/finally1.png' alt='CORS and Capture 2'> <p></p>That's game! Over https, proxying CORS, serving our dynamic lure with no weird certificate errors like this we got earlier when we tried:<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/updog6.png' alt='CORS and Capture 2'><figcaption><i>Warning from using Updog</i></figcaption><p></p>The adhoc SSL certificate updog uses is not trusted, it's self-signed and because Updog is only used for development and testing that doesn't matter.It matters to us, as we need this to look like a quality site. What we essentially are doing is laid out here:<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/diagram1.png' alt='CORS and Capture 2'><p></p>Now we can put our lure together using this and finish the automation. I'm going to include an AWS deploy script, the sorrowset project I use to configure the lure server, capture server, create tmux sessions…basically load your lure and turn the key.<p></p>I'm tired though. Check back for Part 3 where I show you how to turn this whole thing into an infrastructure-as-code solution you can just use. You'll have options and literally everything you need to learn how to make cool cloud stuff your self.<p></p><h5>Check out Part 3:</h5><p></p><a href='https://dev.straylightsecurity.com/'<\/p>",
    image: "https://dev.straylightsecurity.com/assets/cors/8020rule.png",
    clip_path: "polygon(31% 23%, 90% 30%, 50% 100%, 0% 50%)"
  },
  {
    id: 24,
    title: "CORS and Capture Part 1: Dynamic Device Code Phishing",
    date: "03 May 2023",
    description: "<p><p><h1>Dynamic Device Code Phishing</h1><p><p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/corsandcapture1-final.png' alt='CORS and CApture 2'><h2>The Goal</h2><p></p>I decided to focus on device codes as a reliable means of initial access and spent a lot of time working out ways to make it more flexible. Multi-factor authentication and features like Azure AD's conditional access have made phishing for passwords less valuable than it once was. There are a couple of ways to bypass this, one involves using a mitm proxy to capture the authetnication material and another is device code phishing. If you check the resources at the bottom of the page there is information on that flow. I use these logins legitiamtely all the time for logging into services on IoT devices, but even for Azure if I'm authenticating from the command line I usually use device codes to log in. If you are already signed in, all you have to do is open the browser and enter the code to authenticate your session. Generated device codes only live for 15 minutes and it became clear fairly quickly that this limitation was worth stopping what I was doing and taking the time to get a better solution in place. If we can get an access token for the MS Graph, we can use that token to create a Primary Refresh Token for that user. Access tokens are short lived but are refreshed by…you guessed it. With a PRT in hand, we can then refresh our token to each service in O365 that we want to interact with, i.e. Teams, EXO, Sharepoint and loot whatever want. This makes scripting out post-exploitation tasks a breeze and there's some code here later you can use. Access may be short lived in an environment with sharp analysts or good automation, so the goal is to get a long-lasting PRT and as much org recon and user data as possible. If you're wondering what all these tokens we're talking about are, you can check out this PRT Documentation, which should get you up to speed.<p></p><h2>The Problem</h2><p></p>Device codes are only active for 15 minutes, which means our lures are short-lived or the user has to request another code from us. We have been using a template in Outlook and sending it to individual users. We will try to make that work, and will explore hosting the lure as a landing page. This gives the added benefit of tracking click-rate even if the user chooses not to enter the code.<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/server1.png' alt='CORS and CApture 1'><p></p>You can render the page and copy it to create an outlook template.Copy and paste it into a new outlook message, populate the subject and sender if you'd like then 'Save As' Outlook Template file:<p></p><\/p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/bluebeam1.png' alt='CORS and CApture 2'><p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/template1.png' alt='CORS and CApture 1'><p></p>My flow had been to set up three copies of my template, populate the target emails, start a script to trigger a device code and send it to all three targets at the same time. If a user entered the code the script would loot the users email and run all the azure recon I was interested in.<p></p><a href='https://github.com/mellosec/phirstphish'>PhirstPhish.ps1</a><p></p>What I gained in time back was worth the risk of more than one user taking that bait (which never occurred) but this workflow still relies on time of day and people being at their computer, not doing much and and motivated to check it out immediately.<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/template2.png' alt='CORS and CApture 1'><p></p>While working on the write-up, I noticed the grammar correction markup on the template. You should clean this up, and I should, too. You can select to ignore them or add specific words so they don't show up in your targets email. The same principals you'd use for your own business communication should apply to your phishing emails, too.<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/template3.png' alt='CORS and CApture 1'><p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/template4.png' alt='CORS and CApture 1'><p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/template5.png' alt='CORS and CApture 1'><p></p><h2>The Idea</h2><p></p><p></p>Steve Borosh and Bobby Cooke have done a lot of work in this direction and I once again found myself in the Token Tactics repository looking for inspiration. Steve posted a gist from Un1kod3r that would create the device code dyanmically. The app is called CORS-Anywhere and in the gist it's hosted on a decentralized Web3 cloud called Flux. There is a hosted version @ runonflux that worked but when I tried it out I was getting locations from all over. In the past this would have been fine but I've noticed Microsoft has locations and the application you're trying to sign into displayed to the user during the device login flow. Even without things like Conditional Access looking for location based anomalies, this type of signaling could get us in trouble.  I needed to be able to control the location and deploy to the cloud provider of my choosing near clients and this seemed like a great opportunity to learn something new.<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/corsanywhere.png' alt='CORS and Capture 1'><figcaption><i>Nothing sketchy about that.</i></figcaption><p></p>Self hosting the CORS Anywhere turned into a journey of its own and I made a couple of things to help everyone out. I adapted what I could find, modified some of the CORS-Anywhere source code and it's server. This is not secure by default, it's up to you to decide how to handle that. I'll show you how it works and I'll point out some things you can do.<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/corsanywhere2.png' alt='CORS and Capture 1'><figcaption><i>CORS server leaking information</i></figcaption><p></p>With this in place we can proxy requests to the device code endpoint from our project/server and share the same Origin for all requests. What this gives us is a lure with a dynamically generated code embedded. Javascript reaches out to the oauth endpoint when the user opens the email and requests a code which is returned to them paired with the login url:<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/javascript1.png' alt='CORS and Capture 1'><figcaption><i>Requests a device code from the OAuth endpoint</i></figcaption><p></p><h2>The Why</h2>The purpose of the CORS proxy is to bypass the same-origin policy restrictions imposed by the browser when making cross-origin requests from our client-side JavaScript. The same-origin policy dictates that JavaScript running in a web page can only make requests to the same origin (domain, protocol, and port) from which the script was loaded. It is a security mechanism that prevents unauthorized access to resources and protects user data.<p></p>When you use this CORS proxy, the browser makes a request to the proxy server, which acts as an intermediary between the browser and the target server. The proxy server forwards the request to the target server on behalf of the browser. This way, the request appears to be originating from the same domain as the proxy server, bypassing the same-origin policy restrictions.<p></p>The response from the target server is then returned to the browser through the CORS proxy. The proxy server can add appropriate headers to the response to allow the browser to access the requested resource. It then polls the endpoint until it returns the users token and fires that off to our capture server, a flask app waiting to log the token and optionally start TokenTactics. <p></p>The lure will contain something like this:<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/javascript2.png' alt='CORS and Capture 1'><p></p>Which becomes:<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/devicecode.png' alt='CORS and Capture 1'><p></p>The message can be customized to your pretext. We're using a separate EC2 instance to run the CORS Anywhere service  (and eventually the phishing page) on port 80/http and redirect the user to the device code flow. I'll tend to pose as company that would do business with the target and this would be a sharepoint/file subdomain or contractor portal. <p><a href='http://cors.trusteddomain.com/https://microsoft.com/devicelogin'> http://cors.trusteddomain.com/https://microsoft.com/devicelogin </a></p>Where 'cors' is yours CORS app. If you have a high reputation domain this may help you sell the login process in your ruse.<p></p>Once the user signs in, this snippet retrieves the token and sends the code which we capture with a Flask app that logs them.<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/javascript3.png' alt='CORS and Capture 1'><figcaption><i>GET request to our Flask server with the 'id' param containing our captured data</i></figcaption><p></p><h2>Deploying to Azure</h2><p></p>I'm a big fan of Infrastructure-as-Code and have included some scripts to deploy the resources you need. Let's get something to work with, we need PowerShell, Azure CLI and the AWS CLI for later.<p></p><pre class='code-snippet'># Update the list of packages<p></p>sudo apt-get update -y<p></p># Install pre-requisite packages.<p></p>sudo apt-get install -y wget apt-transport-https software-properties-common azure-cli aws unzip<p></p># Download the Microsoft repository GPG keys<p></p>wget -q 'https://packages.microsoft.com/config/ubuntu/$(lsb_release -rs)/packages-microsoft-prod.deb'<p></p># Register the Microsoft repository GPG keys<p></p>sudo dpkg -i packages-microsoft-prod.deb<p></p># Update the list of packages after we added packages.microsoft.com<p></p>sudo apt-get update -y <p></p># Install PowerShell<p></p>sudo apt-get install -y powershell<p></p></pre><p></p>We need an SSH key at ~/.ssh/id_rsa, it will use whatever is there during deployment. This script will create the resources needed in azure, the resource group, VM, networking, etc. <p></p>The script takes parameters: <p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/powershell1.png' alt='CORS and Capture 1'><figcaption><i>Azure Resources to be Created</i></figcaption><p></p>And uses the value of the variable to specify resources to create, open ports, etc:<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/powershell2.png' alt='CORS and Capture 1'><p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/powershell3.png' alt='CORS and Capture 1'><p></p>We use Azure's VM Run-Command feature to start configuring the server from the script:<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/powershell4.png' alt='CORS and Capture 1'><p></p>This is really handy as an admin or engineer and especially so as an attacker. With the right misconfigurations or permissions, an attacker can run scripts and commands on hybrid or On-Prem devices with the right agents installed.<p></p>It will use letsencrypt to acquire a cert:<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/powershell5.png' alt='CORS and Capture 1'><p></p>Now kick off our script and sit back.<p></p><pre class='code-snippet'><p></p># Sign in to Azure<p></p>pwsh<p></p>az login<p></p># dot-source the script<p></p>.  .\capture-server\capture-deploy.ps1<p></p># Call the function to deploy with your values<p></p>Invoke-DeployCaptureServer -ResourceGroup CappaDonna -location eastus -vmName cappadonna -vmPublicDNSName cappadonna -pubKey ~/.ssh/id_rsa.pub</pre><p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/powershell6.png' alt='CORS and Capture 1'><p></p>These resources will be created in Azure:<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/azure1.png' alt='CORS and Capture 1'><p></p><h2>CORS Server and App</h2><p></p>Script will run and continue to run commands on the host to clone repos, open ports, acquires SSL certs and run the deployment script in the yourcors repo<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/azure2.png' alt='CORS and Capture 1'><p></p>The CORS server is a Node app to serve the proxy. The server.js can white/black list, has rate limiting and can check for headers. Let's look at our modified code and break it down:<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/serverjs1.png' alt='CORS and Capture 1'><p></p><pre class='code-snippet'>1. Define the host and port for the CORS Anywhere server. The host is obtained from the HOST environment variable, defaulting to '0.0.0.0', and the port is obtained from the PORT environment variable, defaulting to 8080.<p></p>2. It parses the CORSANYWHERE_BLACKLIST and CORSANYWHERE_WHITELIST environment variables to determine the origin blacklist and whitelist.<p></p>3. It requires the rate-limit module and initializes the checkRateLimit function using the CORSANYWHERE_RATELIMIT environment variable.<p></p>4. It creates a CORS Anywhere server with our custom required headers 'straylight' and 'security' using the cors-anywhere library, providing configuration options such as originBlacklist, originWhitelist, checkRateLimit, removeHeaders, and httpProxyOptions.<p></p>5. The server is then started by calling the listen method, passing the port, host, and a callback function that logs the server's address.<p></p></pre><p></p>I needed firewall rules open while developing this and decided to require a couple of headers to curb any abuse.<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/serverjs2.png' alt='CORS and Capture 1'><p></p>I'm showing you the modified version that is contained in the fork of CORS-Anywhere: https://github.com/mellosec/cors-anywhere. The original 'server.js' and its help file are in a 'references' folder in YOURCORS if you want to see what I changed and removed. The Help file was displayed as an HTTP response, though, it was a red flag we need to clear up. Using a proxy resolves the issue but it's completely removable if we look through the source.<p></p><h2>IoCs and Watermarks</h2>It's important to be mindful of what our tools look like to anyone paying attention. Scanners are always scanning under the watchful eye of ATP and other security products. Palo Alto for example:<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/paloalto1.png' alt='CORS and Capture 1'><p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/helptxt1.png' alt='CORS and Capture 1'><p></p>This used to display everytime you tried '/', which is not ideal. This would make it very clear this was a relay for scanners and shitheads, we removed this, added some unique headers and changed the port. This also allows us to 'watermark' our campaign and provides a clear signal that it was us and not an actual attacker. I plan to add a reverse proxy (caddy) as well but one thing at a time. We've removed the tell tale sign, we're rate limiting, we're opting-out of using any white/black listing and set some custom headers for the api to check.<p></p>Now we can start the server using node.<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/serverjs3.png' alt='CORS and Capture 1'><p></p>Every request needs the headers now to work. Let's test it. <p></p><pre class='code-snippet'><p></p># Test if it's requiring anything to proxy<p></p>curl http://127.0.0.1:8080/<p></p># Test without Headers<p></p>curl http://127.0.0.1:8080/https://s3cur3th1ssh1t.github.io/<p></p># Give S3cur3Th1sSh1t some love<p></p>curl -H 'straylight: value' -H 'security: value' http://127.0.0.1:8080/https://s3cur3th1ssh1t.github.io/<p></p></pre><p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/curl1.png' alt='CORS and Capture 1'><p></p>We can fix that the response telling anyone which headers it's looking for, right?<p></p>Of course we can, it's open source. The file we need to change is in /lib/cors-anywhere.js<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/corsjs1.png' alt='CORS and Capture 1'><p></p>Let's comment out the old code and make our changes.<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/corsjs3.png' alt='CORS and Capture 1'><p></p>The header information is stored in the variable corsAnywhere.requireHeaderBy commenting out the original code we leave a record for handy reference and we make an edit that we will recognize but no one else will understand. You can't rely on security through obscurity but it doesn't hurt either. We can restart our server and move on to updating the lure itself.<p></p><h2>Updating the Lure</h2>Now we need to update the dynamic device page to use our headers. We do this by creating an options object instead of a url object. We store the headers we want in the object and I've added the 'now' as the value for each to help with auditing. The values don't matter, our CORS server is only lookling for 'straylight' and 'security' but those current date and time will give us a nice timestamp.<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/corsjs2.png' alt='CORS and Capture 1'><p></p>To capture the access token, we'll use more javascript and have it return our access token to a simple Flask app running on the capture server:<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/captureserver1.png' alt='CORS and Capture 1'><p></p>This logs Get requests with 'id?=' parameters and stores the arguments as our tokens. It can start powershell for you and pass it to to 'capturetokenphish.ps1' a little scriptlet that's waiting to take the token and pass it to TokenTactics to refresh and store in the cache. I tend to just use them manually but it's here.  You can add your SSL certificates here in 'certs' folder as cert.pem and privkey.pem and it will server over HTTPs. Capture tokens appear in the visitor log:<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/captureserver2.png' alt='CORS and Capture 1'><p></p><h2>But how do we use it?</h2>Once we have one, we can work with it straight from powershell.We will use the captured code with TokeTactics and AADInternals. Save your token as a variable and use it like this:<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/token2.png' alt='CORS and Capture 1'><p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/token2.png' alt='CORS and Capture 1'><p></p><h2>Stand And Deliver</h2>A new foe appeared, and it's sending raw html through Outlook Desktop. Now that we have a bunch of html and javascript doing this dynamically, we can't copy and paste from locally running live server like we were. Now we have to figure out how to send it another way. Like everything else in my life I'll try it with powershell first.<p></p>This post assumes you have your sending set up. I use Office 365, either via trials or dev tenants. You need to set up a custom domain, DNS records for SPF, DKIM, DMARC, etc. Setting that up is beyond but the scope of this article and is a valuable learning experience regardless of your focus in security.<p></p>If you need help check out this article with some terraform and powershell scripts in the repo provided to get up to speed quickly.<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/automated1.png' alt='CORS and Capture 1'><p></p><a href='https://github.com/mellosec/dkimpossible'>DKIMPossible: Onboarding Custom Domains, DNS and mail records for O365 tenants</a><p></p>We're going to take what I showed you above and apply it here to send phishing emails from our own account with powershell. This snippet here is also a good demonstration of how you would acquire a token with TokenTactics and use it with AADInternals in general: <p></p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/graph1.png' alt='CORS and Capture 1'><p></p><pre class='code-snippet'># Get your own access token and refresh it to Outlook <p></p># Targeted User and YOUR domain here <p></p>$user = 'victim@targeted.com'<p></p>$domain = 'trusteddomain.com' <p></p># Get Graph Token with TokenTactics <p></p>Get-AzureToken -Client Graph<p></p>$access = $response.access_token  <p></p> # $response object contains $access<p></p>$refresh = $response.refresh_token <p></p> # and $refresh token<p></p>Add-AADIntAccessTokenToCache -AccessToken $access -RefreshToken $refresh   <p></p>Write-Output 'Refreshing to Outlook token and saving to AADInternals cache'<p></p>$outlook=RefreshTo-OutlookToken -domain $domain     <p></p>Add-AADIntAccessTokenToCache -AccessToken $outlook.access_token -RefreshToken $outlook.refresh_token<p></p># Send something <p></p>$subject = 'A legal document is awaiting your review'<p></p>$SpouseArrested = 'A sensitive document regarding your spouse's arrest is awaiting your review, please follow this $link and enter $code when requested.'<p></p>Send-AADIntOutlookMessage -AccessToken $outlook.access_token -Recipient $user -Subject $subject -Message $SpouseArrested<p></p># Or use an HTML file <p></p>$msg = Get-Content index.html -Raw</pre><p></p><h2>Denied</h2><p></p<p></pNot only did it go straight to junk, the HTML didn't display either.<p></p>We can look at other ways to send HTML through Outlook (macros or options I don't know about), we can troubleshoot sending with powershell, we can try contacting targets over a real-time chat where the codes life doesn't matter as much… I don't like any of those ideas. Point is, when I'm not really confident in my options, I try to wait until something else occurs to me. It's hard to spot a rabbit hole and know when to pull out of one, including rolling your own solutions to problems. It's tough to balance when you don't have time, but I do here so let's ponder.<p></p>While this slows us down, it gave me time to weigh the benefits of a workaround: <p></p>- Hosting the lure as a landing page instead puts another layer between us and O365 email scanning.  Defender for O365 will open the link and check that page, though, as well. I wonder how many pages deep that goes. <p></p>- Hosting it gives us the flexibility of placing other domains or services in front or behind that server.<p></p>- We could use it for hosting our tools with a path-based redirector and/or authentication or C2 in a pinch, we already have a tiny EC2 running the second CORS service on our phishing domain <p></p>- I'd rather build than troubleshoot<p></p>We have a server on that domain that could easily host our lure as a landing page. May as well increase our return on the price of hosting it.<p></p>Updog generates it's own 'adhoc' SSL Certificate to establish HTTPs connection. I think we're going to have problems with the user's browsing displaying warnings but let's see if it could work.<p></p>Updog seems to work for us if we link with ?view:<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/updog1.png' alt='CORS and Capture 1'><p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/updog2.png' alt='CORS and Capture 1'>Let's give it a try.<p></p><h2>Blocked</h2><p></p><p></p>Point of Contact tried the link from a company device and here we are. Get through one barrier, find another. I wonder how our domain got categorized as pornography but either way it's back to the drawing board.<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/blocked1.png' alt='CORS and Capture 1'><p></p>I hate. I am a super-computer programmed only to hate.<p></p>---<p></p>Check out Part 2 and let's see if I lose my mind:<p></p><p><a href='corsandcapture2.html'>CORS and Capture Part 2: Proxy Wars<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/cors/8020rule.png' alt='CORS and Capture 1'> ",
    image: "https://dev.straylightsecurity.com/assets/cors/corsandcapture1-final.png",
    clip_path: "polygon(0 29%, 100% 0, 100% 70%, 48% 100%)"
  },
  {
    id: 25,
    title: "DKIMPossible: Mail Records for O365",
    date: "20 April 2023",
    description: "<p></p><h1>Mail Records for O365</h1><p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/dkimpossible-final.png' alt='DKIMPossible'><p></p> I wanted to learn what it takes to get through Microsoft's security stack. I couldn't land an email anywhere and I almost got my home IP banned by Spamhaus. I ended up buying an expired domain through expireddomains.net with good rating and a lot of backlinks. I grabbed some Office licenses and started the tedious process of setting up records. I wanted to help out with that (and never ever have to do it again) and it seemed like a perfect project for terraform. I ended up writing a powershell helper script to handle the changes in O365 and terraform updates the DNS in either GoDaddy, Namecheap or DigitalOcean. I will add AWS and Azure at some point. <p></p>Through amazing blogs by Steve Borosh's 'Spoofing Microsoft 365 Like It's 1995', Bobby Cook's 'The Art of the Device Code Phish', and 'Long Live DMARC - Email Spoof issues' by Intruder at redteamcafe, I set up all the SPF and DKIM records which got my mail rating to a 9.5 on https://mail-tester.com. I emailed myself at the target organization and verified it's delivery. It was tedious and boring. I started thinking of ways to automate it and this what I came up with. Let's look at what we're up against:<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/dkimpossible/dkimpossible2.png' alt='DKIMPossible'><figcaption><i>Exchange Online Protection flow from Steve's article</i></figcaption><p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/dkimpossible/dkimpossible3.png' alt='DKIMPossible'><figcaption><i>Intruder's breakdown of SPF and DKIM</i></figcaption><p></p>Here's the project structure, we're going to use Terraform and Powershell<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/dkimpossible/dkimpossible4.png' alt='DKIMPossible'><p></p><h4>Helper Script</h4><p></p>Each template has a helper script  AzNameCheap.ps1, AzGoDaddy.ps1, AzDigitalOcean.ps1 that takes a domain as a parameter. This is run in the same folder as the terraform project, it will run terraform for you. <p></p>It will install and import the modules you need, get your admin creds for the tenant and create the domain.<p></p> Then it runs a plan and waits for you to confirm before applying the changes. <p></p> Once changes are made and the records are live, the DKIM Signing is enabled. <p></p> Go into the portal and check to make sure the custom domain is verified in Azure AD under 'custom domains' and in O365. Then check https://security.microsoft.com/dkim and verify them there as well.<p></p> May as well check your providers dashboard as well to verify everything got where it was supposed to. Terraform is pretty good about minding it's own shop but best practice is good practice.<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/dkimpossible/dkimpossible5.png' alt='DKIMPossible'><figcaption><i>Powershell to deploy Terraform</i></figcaption><p></p><h4>Providers.tf</h4><p></p>Here's our providers file, this is where you tell terraform what provider you want to use. Terraform supports a bunch of non-cloud APIs as well, for example I've used it to spin up VMs on Proxmox. You can find third party providers or use hashicorp's which give you the documentation with examples.  There are better ways to do this where you don't enter your actual API keys in the project files using Vault.  We should learn that next. Those variables won't work, those are just for me to you so you know what goes where. These values come from your DNS providers dashboard where you'll create your API keys.<img class='post-article__image' src='https://dev.straylightsecurity.com/assets/dkimpossible/dkimpossible6.png' alt='DKIMPossible'><figcaption><i>Namecheap requires an IP Address and API key</i></figcaption><p></p><h4>Main.tf</h4><p></p>Main.tf, the main part of the project, unsurprisingly. We define some variables up top for the domain name and incidentals like GoDaddy's customer Id. Each provider has their own way of doing things that are slightly different. Some people put these in their own variables file but I like being able to look at it in the same file since we're not doing anything too complicated. Notice domain has a '-' so '-com' rather than '.com'. <p></p>These values come from your tenant. The customer Id is a godaddy thing only and isn't required for everyone, but the tenant suffix / onmirosoft domain and the verification record come from the AzureAD tenant you're phishing from.I added the protection ones as variables as well, even though the structure doesn't change, this let's me loook back at this later and know what's important. Run the powershell script attached to each template, it will give you the value you need for 'verification_record'<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/dkimpossible/dkimpossible7.png' alt='DKIMPossible'><figcaption><i>Replace with your values</i></figcaption><p></p><h4>DNS and SPF Records</h4>DNS Records to be created. We have our verification record, the SPF record and the MX protection record.<p></p>Sender Policy Framework (SPF) is an email authentication technique used to prevent email spoofing and spam by validating the origin of an email message. It works by allowing domain owners to specify which mail servers are authorized to send emails on their behalf. This information is published as a DNS record, known as an SPF record. When an email is received, the recipient's mail server checks the sending server's IP address against the authorized servers listed in the domain's SPF record. If the sending server is found in the list, the email is considered legitimate; otherwise, it may be marked as spam or rejected. <p></p>If you are going to use something like GoPhish you may want to add a SPF record for that public IP, as well, but that's way outside the scope of this post (and something I haven't done yet).<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/dkimpossible/dkimpossible8.png' alt='DKIMPossible'><figcaption><i>GoDaddy example</i></figcaption><p></p>DKIM CNAMES  and enterprise endpoints make up the rest of the project. We'll look at each a little closer. <p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/dkimpossible/dkimpossible9.png' alt='DKIMPossible'><figcaption><i>DKIM uses CNAME Records</i></figcaption><p></p>This is where we set up DKIM for the domain. <p></p>DomainKeys Identified Mail (DKIM) is an email authentication method designed to improve email security and help prevent email spoofing, phishing, and spam. It enables the sender to cryptographically sign an email message using a private key, which is then verified by the recipient using a public key published in the sender's Domain Name System (DNS) record. <p></p>By validating the signature, the recipient can confirm that the email has not been tampered with during transit and that it genuinely originates from the claimed domain. This process helps to establish trust and credibility in email communications, ensuring the integrity of the email ecosystem. We set the records here with the variables from above.<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/dkimpossible/dkimpossible10.png' alt='DKIMPossible'><p></p>Enterprise enrollment records just to look like every other O365 org:<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/dkimpossible/dkimpossible11.png' alt='DKIMPossible'><figcaption><i>O365 Enterprise enrollment</i></figcaption><p></p>Kick it off with the powershell script and enjoy about 3 hours of your time back. If it sucks or it breaks, let me know please.<p></p><a href='https://github.com/mellosec/dkimpossible'>DKIMPossible</a><p></p><h2>Resources</h2><a href='https://github.com/mellosec/dkimpossible'>Terraform/Powershell project in the article</a><p></p>  <a href='https://www.blackhillsinfosec.com/spoofing-microsoft-365-like-its-1995/'> Spoofing Microsoft 365 Like It's 1995 - Black Hills Information Security (blackhillsinfosec.com)</a><p></p>    <p></p><a href='https://0xboku.com/2021/07/12/ArtOfDeviceCodePhish.html'>Art of the Device Code Phish</a><p></p><p></p><a href='https://www.redteam.cafe/phishing/long-live-dmarc-email-spoof-issues'>Long Live DMARC</a><p></p><p></p><a href='https://mail-tester.com'>Check your mail rating</a><p></p><a href='https://dirteam.com/bas/2020/08/17/field-notes-dkim-and-missing-selector-records/'>For DKIM Woes</a>    <p></p> <\/p>",
    image: "https://dev.straylightsecurity.com/assets/dkimpossible-final.png",
    clip_path: "polygon(24% 0, 90% 30%, 79% 78%, 13% 76%)"
  },
    {
    id: 26,
    title: "Sleeping Giants: Learning to Phish",
    date: "5 April 2023",
    description: "<p><p><h1>Learning to Phish</h1><p><p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/sleepinggiants.png' alt='Sleeping Giants'><h2>The Hardest Part</h2><p></p>One skill I've wanted to improve is phishing. I spend a lot of time staring at terminals and internal networks with a big focus on what happens once you get in. I felt there was a gap in my knowledge and wanted to see for myself what it takes to get in. Most organizations I come across use O365 in some capacity, and with my experience administering it, setting up a new lab would be straightforward. I needed a good environment that covered the types of problems I would encounter. My current lab is a hybrid Active Directory environment and I decided to build that out, adding Microsoft Defender for Office/Endpoint, some Conditional Access policies with Multi-Factor Authetnication. With a target in place, I set out to put the right toolkit together and make myself some documentation to follow so that my focus could be  more on the interpersonal aspects and less on powershell. I knew this would be a complicated process and gave myself plenty of time to experiment, but even with a month or two of lead-up it was tough and there were some insights gained that I think may benefit others. I tried to automate the sticky bits and put something flexible together with recovery in mind. The same infrastructure can be deployed for as many domains as you have and want and if something gets burned (and it did) you have options. In some ways, this will serve to save you some time sifting through articles from a year or two that no longer work, too. As the arms race continues, some of the techniques and tools don't work as well as they once did. I'll try and highlight these things along the way. In some ways, this will serve to save you some time sifting through articles from a year or two that no longer work. <p></p><h2>Domains</h2><p></p>  I found the most success with expireddomains.net and selecting sites with a decent reputation, some backlinks, etc. In retrospect, I should have checked the cateogories for something that would bypass web filters. It will be probably tough to find a perfect typosquat domain like your targets but if you're going to  be engaging in social engineering you can find something to work with your pre-text. I chose a few companies with good scores that would feasibly do work and interact with my type of clients. This allowed me to reach out with business inquiries and talk shop on linkedin. Pick something you can back up with a little knowledge; if you have no experience in a legal setting don't overreach with a legal profession pre-text when you could instead be a potential client who would be expected to sound lost and ask questions.Namecheap is cheaper than GoDaddy but GoDaddy seems to be a little easier to work with as far as Terraform. Some domains you want are only listed as GoDaddy or Namecheap. It is worth throwing the domain into that providers site and see if they offer it. I've found the same domains on namecheap for about 4 dollars less at times.<p><p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/sleeping/sleeping1.png' alt='Sleeping Giants'><p></p><h2>Mail Sending Service</h2><p></p>O365 likes to trust O365, with my Microsoft background and current tenant an Office subscription seemed like the best move. I have seen Mailgun listed as a good service that's highly recommended. I opted for using my dev tenant to see what could be done with O365. Dev tenants are free and supply you with a ton of licenses as long as you use it for development projects every now and then. This in combination with free credits from Pay-as-You-Go for your first year of services you can get a good lab together cheap.<p></p><a href='https://developer.microsoft.com/en-us/microsoft-365/dev-program'>Free Dev tenant with licenses</a><p></p>You can get an O365 dev tenant for free with a number of licenses and pre-populated users. I highly, highly recommend getting one, espeically if you've any interest in Azure. It will allow you to work with AAD/Conditional Access, Defender for Endpoint licenses for an EDR lab, etc. Seriously, it's free and they wont close it down as long as you work on some projects and use it regularly. You'll also need a regular Azure tenant to deploy the App Service components later on in this post.It's a very Azure-centric blog but I try to keep it free as much as I can. With one of these tenants and a Pay-as-You-Go subscription with free serrvices for a year you can play with just about everything.<p></p><h2>Mail Reputation</h2><p></p>Your next quest is adding a custom domain to your Azure AD tenant, adding DNS records at your provider for sending mail, enrollment services and setup DKIM keys.I made a powershell/terraform project to help you with this. There are a couple of manual steps but it's a huge time saver:<p></p><a href='https://github.com/mellosec/dkimpossible'>DKIMPossible</a><p></p><a href='dkimpossible.html'>Tool writeup</a><p></p>When you get your domain setup, create yourself a user in Azure Active Directory and assign it the required licensing for email. For the dev tenant there's a basket license that contains everything you have available, if you're using your own subscription you may need to start an Office 365 trial or assign a license.<p></p><p></p>Create a test email with barely anything. Make it seem normal. I like to do a 'Hey Mark,  let me know if you get this please. We're working with a new email provider and haven't worked out all the kinks yet. Wish us luck!' something like that. Even before bing was reading everything Outlook would look for 'spammy' text and make value determinations on your email. By doing this it seems like a normal testing situation rather than what it is. It may not make much of a difference but in the advent of Large Language Models I consider it good opsec to think you're always being evaluated by something like that.<p></p>Go to <a href='mail-tester.com'>mail-tester.com</a> and see what we're working with<p></p><p><p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/sleeping/sleeping2.png' alt='Sleeping Giants'><p></p><figcaption><i>Mail Score</i></figcaption><p></p>Fire it off to the address the site gives you and it will give you a score based on a number of factors. It will explain what the problem is:<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/sleeping/sleeping2a.png' alt='Sleeping Giants'><p></p><h2>Pictures, Links and Lures</h2><p></p>Don't send pictures in the email, the Exchange gods don't like it. Don't send clickable links, and be mindful of the reputation of the link you are sending. I remove the hyperlink from the url, it will still be clickable. You can use custom domains with SSL certificates easily on App Service and those are high quality certificates. I'll host a redirector on a custom domain app service that redirects to another app service or wherever I need it. Azure-App-Tools by rvrsh3ll... <p></p><a href='https://github.com/rvrsh3ll/Azure-App-Tools'>Azure App Tools</a><p></p>...has Python-Flask-Redirector that looks useful here. It can be modifed to redirect to the endpoints we need a couple different ways.<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/sleeping/sleeping3.png' alt='Sleeping Giants'><p></p>I like creating simple html/css emails and landing pages that link to pictures rather than include them. I'll try to find a photo on the vendor's site or host something I made to add to the con.<p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/sleeping/sleeping4.png' alt='Sleeping Giants'><p></p>Not my bucket, and using wikipedia. Better than nothing but if you can find something official it will make your lure look more legit and prevent a distinct IoC like this. That said, it works.<p></p><img class='post-article__image' src='https://dev.straylightsecurity.com/assets/sleeping/sleeping5.png' alt='Sleeping Giants'><p></p><p></p>Save it as an outlook template file and save yourself some trouble. I'm sure there are better ways with something like GoPhish but I wanted to try and figure it all out manually first. If you save the template you can open a few, paste some addresses, and trigger a device code to send.<p></p>At this point, we tried our first couple of waves of phishing and while they arrived successfully, no one took the bait. The time-sensitive nature of device codes led me into looking for a solution to serve them dynamically. That way when a user opens the email the timer starts there. Maybe we can figure out a better way. <p></p>To be continued...<p></p>The CORS and Capture series and DKIMPossible continue the journey down this road.<p></p><h2>Resources</h2><a href='https://learn.microsoft.com/en-us/azure/active-directory/develop/v2-oauth2-device-code'>Device Code Flow overview from Identity Platform docs</a><p></p>    <p></p><a href='https://www.synacktiv.com/en/publications/azure-ad-introduction-for-red-teamers'>Azure primer for Red Teamers to get you up to speed:</a><p></p><p></p><a href='https://www.trustedsec.com/blog/hacking-your-cloud-tokens-edition-2-0/'>    Good Token Abuse Writeup by TrustedSec:</a><p></p><\/p>",
    image: "https://dev.straylightsecurity.com/assets/sleepinggiants.png",
    clip_path: "polygon(50% 0, 90% 30%, 79% 78%, 13% 76%)"
  }
];

const app = new Vue({
  el: "#app",
  data() {
    return {
      test: "",
      posts: posts,
      selectedClipPath: "polygon(0 100%, 0 0, 100% 0, 100% 100%)",
      postImage: posts[0].image,
      currentPost: null,
      postIndex: 0,
      selected: false,
      ready: false,
      lastSelectedPost: null,
      clipPath: posts[0].clip_path
    };
  },
  methods: {
    changePost(index) {
      if (this.postImage != this.posts[index].image && this.selected == false) {
        this.postImage = this.posts[index].image;
        this.clipPath = this.posts[index].clip_path;
      }
    },
    closePost() {
      if(this.lastSelectedPost != null){
        this.selected = false;
        this.ready = false;
        this.clipPath = this.posts[this.lastSelectedPost].clip_path;
      }
    },
    selectedPost(index) {
      this.selected = true;
      this.clipPath = this.selectedClipPath;
      this.lastSelectedPost = index;
      this.currentPost = this.posts[index];
      // We added this to create a fragment identifier for the "id"
      // The URL will show site.com/#post1
      // window.location.hash = this.currentPost.id;
      window.location.hash = String(this.currentPost.id);
      setTimeout(() => {
        this.ready = true;
      }, 600);
    },
    nextPost() {
      if (this.lastSelectedPost < this.posts.length - 1) {
        this.lastSelectedPost++;
        this.ready = false;
        setTimeout(() => {
          this.currentPost = this.posts[this.lastSelectedPost];
          this.postImage = this.currentPost.image;
          this.ready = true;
        }, 600);
      }
    },
    prevPost() {
      if (
        this.lastSelectedPost <= this.posts.length - 1 &&
        this.lastSelectedPost != 0
      ) {
        this.lastSelectedPost--;
        this.ready = false;
        setTimeout(() => {
          this.currentPost = this.posts[this.lastSelectedPost];
          this.postImage = this.currentPost.image;
          this.ready = true;
        }, 600);
      }
    }
  },
  created() {
    window.addEventListener("keydown", e => {
      if (e.keyCode === 39) this.nextPost();
      if (e.keyCode === 37) this.prevPost();
      if (e.keyCode === 27) this.closePost();
    });
  
    // If a hash is present in the URL when the page is loaded, select the corresponding post
    if (window.location.hash) {
      const postId = window.location.hash.substring(1); // remove the '#' from the start of the hash
      const postIndex = this.posts.findIndex(post => String(post.id) === postId);
      if (postIndex !== -1) { // if a post with the id from the hash was found
        this.selectedPost(postIndex);
      }
    }
  }
  
  });
